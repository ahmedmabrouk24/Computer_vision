{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1BrYJQo4Soz0O2126wSPNl8OFwqhkKA9e",
      "authorship_tag": "ABX9TyNXJAoiLimldIpcdkdAJc7m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedmabrouk24/Computer_vision/blob/main/test_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3vDavqcLCn5",
        "outputId": "f8599499-3fb7-4fd3-9cf0-754e0912af66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tflearn\n",
            "  Downloading tflearn-0.5.0.tar.gz (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from tflearn) (7.1.2)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127299 sha256=d1676f265e010f8f79ea26c7f14c284e753e637870bcec442cc3ca5537e896f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/9b/15/cb1e6b279c14ed897530d15cfd7da8e3df8a947e593f5cfe59\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n"
          ]
        }
      ],
      "source": [
        "pip install tflearn "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras import layers,models,Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Activation, Flatten, Dropout, BatchNormalization, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from skimage.feature import hog\n",
        "from sklearn.svm import SVC\n",
        "from keras.saving.save import load_model\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import numpy as np\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import json\n",
        "import pickle\n",
        "\n"
      ],
      "metadata": {
        "id": "-7Lol5t1Lf_z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Test_DIR_A = '/content/drive/MyDrive/Computer Vision/Dataset_1/personA/Test'\n",
        "Test_DIR_B = '/content/drive/MyDrive/Computer Vision/Dataset_1/personB/Test'\n",
        "Test_DIR_C = '/content/drive/MyDrive/Computer Vision/Dataset_1/personC/Test'\n",
        "Test_DIR_D = '/content/drive/MyDrive/Computer Vision/Dataset_1/personD/Test'\n",
        "Test_DIR_E = '/content/drive/MyDrive/Computer Vision/Dataset_1/personE/Test'\n",
        "Test_DIR=[]\n",
        "Test_DIR.append(Test_DIR_A)\n",
        "Test_DIR.append(Test_DIR_B)\n",
        "Test_DIR.append(Test_DIR_C)\n",
        "Test_DIR.append(Test_DIR_D)\n",
        "Test_DIR.append(Test_DIR_E)\n",
        "\n",
        "MODELS_DIR = \"/content/drive/MyDrive/vision models\" \n",
        "recognition_model = load_model('/content/drive/MyDrive/vision models/person_Recognetion.h5')\n",
        "modelA = pickle.load(open(\"/content/drive/MyDrive/vision models/modelA\", 'rb'))\n",
        "modelB = pickle.load(open(\"/content/drive/MyDrive/vision models/modelB\", 'rb'))\n",
        "modelC = pickle.load(open(\"/content/drive/MyDrive/vision models/modelC\", 'rb'))\n",
        "modelD = pickle.load(open(\"/content/drive/MyDrive/vision models/modelD\", 'rb'))\n",
        "modelE = pickle.load(open(\"/content/drive/MyDrive/vision models/modelE\", 'rb'))\n",
        "\n",
        "TEST_SCRIPT_DIR = \"/content/drive/MyDrive/test_script_data\"\n",
        "IMG_SIZE = 200"
      ],
      "metadata": {
        "id": "v6XYRdk1LYqI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for test_img in os.listdir(TEST_SCRIPT_DIR):\n",
        "    X_test_f = []\n",
        "    path = os.path.join(TEST_SCRIPT_DIR, test_img)\n",
        "    img_data = cv2.imread(path, 0) \n",
        "    img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n",
        "    feature_discriptor, hog_img = hog(img_data, orientations = 9, pixels_per_cell = (8, 8),cells_per_block = (2, 2), visualize = True, multichannel = False)\n",
        "    X_test_f.append(feature_discriptor)\n",
        "\n",
        "    X_test = np.array(img_data).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "    Y_pred = recognition_model.predict(X_test)\n",
        "    prediction = np.argmax(Y_pred)\n",
        "    print(test_img)\n",
        "    if (prediction == 0):\n",
        "        realOrNot = modelA.predict(X_test_f)\n",
        "        if (realOrNot == 0):print(\"This is Person A Forgerd signature\")\n",
        "        else :print(\"This is Person A Forgerd signature\")\n",
        "        print()\n",
        "\n",
        "    elif(prediction == 1):\n",
        "        realOrNot = modelB.predict(X_test_f)\n",
        "        if (realOrNot == 0):print(\"This is Person B Forgerd signature\")\n",
        "        else :print(\"This is Person B Forgerd signature\")\n",
        "        print()\n",
        "\n",
        "    elif(prediction == 2):\n",
        "        realOrNot = modelC.predict(X_test_f)\n",
        "        if (realOrNot == 0):print(\"This is Person C Forgerd signature\")\n",
        "        else :print(\"This is Person C Forgerd signature\")\n",
        "        print()\n",
        "\n",
        "    elif(prediction == 3):\n",
        "        realOrNot = modelD.predict(X_test_f)\n",
        "        if (realOrNot == 0):print(\"This is Person D Forgerd signature\")\n",
        "        else :print(\"This is Person D Forgerd signature\")\n",
        "        print()\n",
        "\n",
        "    elif(prediction == 4):\n",
        "        realOrNot = modelE.predict(X_test_f)\n",
        "        if (realOrNot == 0):print(\"This is Person E Forgerd signature\")\n",
        "        else :print(\"This is Person E Real signature\")\n",
        "        print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ypWfcC-MOtB",
        "outputId": "f1f5450a-393a-4d4b-9fef-dd012b43195e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "personA_29.png\n",
            "This is Person A Forgerd signature\n",
            "\n",
            "personB_10.png\n",
            "This is Person B Forgerd signature\n",
            "\n",
            "personD_14.png\n",
            "This is Person D Forgerd signature\n",
            "\n",
            "personE_15.png\n",
            "This is Person E Real signature\n",
            "\n",
            "personC_6.png\n",
            "This is Person C Forgerd signature\n",
            "\n"
          ]
        }
      ]
    }
  ]
}