{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedmabrouk24/Computer_vision/blob/main/person_Recognetion_with_logs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tflearn "
      ],
      "metadata": {
        "id": "BmzWo4g4u89I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4994ed62-0129-49fd-c682-f8e3ce3901e2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tflearn in /usr/local/lib/python3.8/dist-packages (0.5.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from tflearn) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml h5py  # Required to save models in HDF5 format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfMPjgM2oZH_",
        "outputId": "0e458763-8753-405d-938f-f28a359cb125"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.5 in /usr/local/lib/python3.8/dist-packages (from h5py) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SyKJ1f1WSK10"
      },
      "outputs": [],
      "source": [
        "from random import shuffle\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras import layers,models,Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Activation, Flatten, Dropout, BatchNormalization, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from keras.saving.save import load_model\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_DIR_A = '/content/drive/MyDrive/Computer Vision/Dataset_1/personA/Train'\n",
        "TRAIN_DIR_B = '/content/drive/MyDrive/Computer Vision/Dataset_1/personB/Train'\n",
        "TRAIN_DIR_C = '/content/drive/MyDrive/Computer Vision/Dataset_1/personC/Train'\n",
        "TRAIN_DIR_D = '/content/drive/MyDrive/Computer Vision/Dataset_1/personD/Train'\n",
        "TRAIN_DIR_E = '/content/drive/MyDrive/Computer Vision/Dataset_1/personE/Train'\n",
        "TRAIN_DIR=[]\n",
        "TRAIN_DIR.append(TRAIN_DIR_A)\n",
        "TRAIN_DIR.append(TRAIN_DIR_B)\n",
        "TRAIN_DIR.append(TRAIN_DIR_C)\n",
        "TRAIN_DIR.append(TRAIN_DIR_D)\n",
        "TRAIN_DIR.append(TRAIN_DIR_E)\n",
        "\n",
        "\n",
        "Test_DIR_A = '/content/drive/MyDrive/Computer Vision/Dataset_1/personA/Test'\n",
        "Test_DIR_B = '/content/drive/MyDrive/Computer Vision/Dataset_1/personB/Test'\n",
        "Test_DIR_C = '/content/drive/MyDrive/Computer Vision/Dataset_1/personC/Test'\n",
        "Test_DIR_D = '/content/drive/MyDrive/Computer Vision/Dataset_1/personD/Test'\n",
        "Test_DIR_E = '/content/drive/MyDrive/Computer Vision/Dataset_1/personE/Test'\n",
        "Test_DIR=[]\n",
        "Test_DIR.append(Test_DIR_A)\n",
        "Test_DIR.append(Test_DIR_B)\n",
        "Test_DIR.append(Test_DIR_C)\n",
        "Test_DIR.append(Test_DIR_D)\n",
        "Test_DIR.append(Test_DIR_E)\n",
        "\n",
        "\n",
        "train_images=[]\n",
        "test_images=[]\n",
        "\n",
        "\n",
        "IMG_SIZE = 200\n",
        "num_classes = 5\n",
        "MODEL_NAME = 'signature_model1'\n"
      ],
      "metadata": {
        "id": "QoqKQhetg5L9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_train_data():\n",
        "    training_data = []\n",
        "\n",
        "    for path_TRAIN_DIR in tqdm(TRAIN_DIR):\n",
        "       for img in os.listdir(path_TRAIN_DIR):\n",
        "        if 'csv' in img:\n",
        "          continue\n",
        "        path = os.path.join(path_TRAIN_DIR, img)\n",
        "        img_data = cv2.imread(path,0) \n",
        "        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n",
        "        training_data.append([np.array(img_data),ord(img[6])-ord('A') ])\n",
        "\n",
        "    random.shuffle(training_data)\n",
        "\n",
        "    return training_data\n"
      ],
      "metadata": {
        "id": "AivLBvlWj5QL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column1=[]\n",
        "def create_test_data():\n",
        "    test_data = []\n",
        "\n",
        "    for path_Test_DIR in tqdm(Test_DIR):\n",
        "       for img in os.listdir(path_Test_DIR):\n",
        "        if 'csv' in img:\n",
        "          continue\n",
        "        column1.append(img)\n",
        "        path = os.path.join(path_Test_DIR, img)\n",
        "        img_data = cv2.imread(path,0) \n",
        "        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n",
        "        test_data.append([np.array(img_data),ord(img[6])-ord('A') ])\n",
        "       \n",
        "\n",
        "    #random.shuffle(test_data)\n",
        "    return test_data\n"
      ],
      "metadata": {
        "id": "j-ujRT0IsCax"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = create_train_data()\n",
        "X_train = np.array([i[0] for i in train_images]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "y_train = np.array([i[1] for i in train_images]).reshape(-1,)\n",
        "\n",
        "test_images = create_test_data()\n",
        "X_test = np.array([i[0] for i in test_images]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "y_test = np.array([i[1] for i in test_images]).reshape(-1,)"
      ],
      "metadata": {
        "id": "eejyrnehsvU_",
        "outputId": "1c6f9a79-dd90-46df-e363-eb4d53a7e02b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:31<00:00,  6.35s/it]\n",
            "100%|██████████| 5/5 [00:05<00:00,  1.12s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model1 = Sequential([\n",
        "        layers.Conv2D(filters = 16 ,kernel_size = (3, 3), input_shape = (IMG_SIZE, IMG_SIZE, 1), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size = (2,2)),\n",
        "\n",
        "        layers.Conv2D(filters = 32 ,kernel_size = (5, 5), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    \n",
        "        layers.Conv2D(filters = 32 ,kernel_size = (5, 5), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    \n",
        "        layers.Conv2D(filters = 16 ,kernel_size = (3, 3), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2,2)),\n",
        "  \n",
        "        layers.Flatten(),\n",
        "        layers.Dense(1024, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        layers.Dense(5, activation = 'softmax')\n",
        "])\n",
        "\n",
        "model1.compile(\n",
        "    optimizer= tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
        "    loss=SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'])\n",
        "if (os.path.exists('/content/drive/MyDrive/person_Recognetion.h5')):\n",
        "      model1 = load_model('/content/drive/MyDrive/person_Recognetion.h5')\n",
        "else:\n",
        "      model1.fit(X_train, y_train, epochs = 10)\n",
        "      model1.save('/content/drive/MyDrive/person_Recognetion.h5')\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "fS-3mhEZt_mQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model1.evaluate(X_test,y_test))"
      ],
      "metadata": {
        "id": "cG7HePfrstc2",
        "outputId": "53914abe-e56f-4ca5-90d7-002cf37c94cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.28012554720044136, 0.875]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test=model1.predict(X_test)\n",
        "print(len(X_test))\n",
        "prediction=[]\n",
        "for i in Y_test:\n",
        "  prediction.append(np.argmax(i))\n",
        "data={'image_name':column1,'label':prediction[:40]}\n",
        "print(len(column1),len(prediction))\n",
        "df_person=pd.DataFrame(data)\n",
        "print(df_person)\n"
      ],
      "metadata": {
        "id": "ImwoJGryeZMc",
        "outputId": "2ac1d026-09e9-42cd-f36c-e9af4b25bf8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40\n",
            "40 40\n",
            "        image_name  label\n",
            "0   personA_10.png      1\n",
            "1   personA_13.png      4\n",
            "2    personA_2.png      4\n",
            "3   personA_20.png      0\n",
            "4   personA_27.png      0\n",
            "5   personA_29.png      4\n",
            "6   personA_30.png      0\n",
            "7   personA_42.png      4\n",
            "8   personB_10.png      1\n",
            "9   personB_13.png      1\n",
            "10   personB_2.png      1\n",
            "11  personB_20.png      1\n",
            "12  personB_27.png      1\n",
            "13  personB_29.png      1\n",
            "14  personB_33.png      1\n",
            "15  personB_42.png      1\n",
            "16  personC_13.png      2\n",
            "17  personC_17.png      2\n",
            "18  personC_19.png      2\n",
            "19  personC_32.png      2\n",
            "20  personC_34.png      2\n",
            "21  personC_39.png      2\n",
            "22   personC_6.png      2\n",
            "23   personC_8.png      2\n",
            "24  personD_14.png      3\n",
            "25  personD_15.png      3\n",
            "26  personD_17.png      3\n",
            "27  personD_21.png      3\n",
            "28  personD_22.png      3\n",
            "29  personD_26.png      3\n",
            "30  personD_31.png      3\n",
            "31  personD_41.png      3\n",
            "32  personE_15.png      4\n",
            "33  personE_17.png      4\n",
            "34  personE_18.png      4\n",
            "35  personE_22.png      4\n",
            "36  personE_27.png      4\n",
            "37  personE_32.png      4\n",
            "38  personE_35.png      4\n",
            "39  personE_40.png      4\n"
          ]
        }
      ]
    }
  ]
}