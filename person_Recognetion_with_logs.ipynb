{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedmabrouk24/Computer_vision/blob/main/person_Recognetion_with_logs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tflearn "
      ],
      "metadata": {
        "id": "BmzWo4g4u89I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fb5c97b-d3dc-48ea-9fcd-e3d29490572e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tflearn\n",
            "  Downloading tflearn-0.5.0.tar.gz (107 kB)\n",
            "\u001b[K     |████████████████████████████████| 107 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from tflearn) (7.1.2)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127299 sha256=90f7ea878ff280cbacff0640e8a903419ea3ed75eade1e213862fa467611b9dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/9b/15/cb1e6b279c14ed897530d15cfd7da8e3df8a947e593f5cfe59\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml h5py  # Required to save models in HDF5 format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfMPjgM2oZH_",
        "outputId": "08e5ac6e-75c5-48e9-c5b8-11d44571e571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.5 in /usr/local/lib/python3.8/dist-packages (from h5py) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyKJ1f1WSK10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35801b79-5413-47b5-bce2-3b62757577b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "from random import shuffle\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras import layers,models,Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Activation, Flatten, Dropout, BatchNormalization, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from keras.saving.save import load_model\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_DIR_A = '/content/drive/MyDrive/Computer Vision/Dataset_1/personA/Train'\n",
        "TRAIN_DIR_B = '/content/drive/MyDrive/Computer Vision/Dataset_1/personB/Train'\n",
        "TRAIN_DIR_C = '/content/drive/MyDrive/Computer Vision/Dataset_1/personC/Train'\n",
        "TRAIN_DIR_D = '/content/drive/MyDrive/Computer Vision/Dataset_1/personD/Train'\n",
        "TRAIN_DIR_E = '/content/drive/MyDrive/Computer Vision/Dataset_1/personE/Train'\n",
        "TRAIN_DIR=[]\n",
        "TRAIN_DIR.append(TRAIN_DIR_A)\n",
        "TRAIN_DIR.append(TRAIN_DIR_B)\n",
        "TRAIN_DIR.append(TRAIN_DIR_C)\n",
        "TRAIN_DIR.append(TRAIN_DIR_D)\n",
        "TRAIN_DIR.append(TRAIN_DIR_E)\n",
        "\n",
        "\n",
        "Test_DIR_A = '/content/drive/MyDrive/Computer Vision/Dataset_1/personA/Test'\n",
        "Test_DIR_B = '/content/drive/MyDrive/Computer Vision/Dataset_1/personB/Test'\n",
        "Test_DIR_C = '/content/drive/MyDrive/Computer Vision/Dataset_1/personC/Test'\n",
        "Test_DIR_D = '/content/drive/MyDrive/Computer Vision/Dataset_1/personD/Test'\n",
        "Test_DIR_E = '/content/drive/MyDrive/Computer Vision/Dataset_1/personE/Test'\n",
        "Test_DIR=[]\n",
        "Test_DIR.append(Test_DIR_A)\n",
        "Test_DIR.append(Test_DIR_B)\n",
        "Test_DIR.append(Test_DIR_C)\n",
        "Test_DIR.append(Test_DIR_D)\n",
        "Test_DIR.append(Test_DIR_E)\n",
        "\n",
        "\n",
        "train_images=[]\n",
        "test_images=[]\n",
        "\n",
        "\n",
        "IMG_SIZE = 200\n",
        "num_classes = 5\n",
        "MODEL_NAME = 'signature_model1'\n"
      ],
      "metadata": {
        "id": "QoqKQhetg5L9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_train_data():\n",
        "    training_data = []\n",
        "\n",
        "    for path_TRAIN_DIR in tqdm(TRAIN_DIR):\n",
        "       for img in os.listdir(path_TRAIN_DIR):\n",
        "        if 'csv' in img:\n",
        "          continue\n",
        "        path = os.path.join(path_TRAIN_DIR, img)\n",
        "        img_data = cv2.imread(path,0) \n",
        "        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n",
        "        training_data.append([np.array(img_data),ord(img[6])-ord('A') ])\n",
        "\n",
        "    random.shuffle(training_data)\n",
        "\n",
        "    return training_data\n"
      ],
      "metadata": {
        "id": "AivLBvlWj5QL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column1=[]\n",
        "def create_test_data():\n",
        "    test_data = []\n",
        "\n",
        "    for path_Test_DIR in tqdm(Test_DIR):\n",
        "       for img in os.listdir(path_Test_DIR):\n",
        "        if 'csv' in img:\n",
        "          continue\n",
        "        column1.append(img)\n",
        "        path = os.path.join(path_Test_DIR, img)\n",
        "        img_data = cv2.imread(path,0) \n",
        "        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n",
        "        test_data.append([np.array(img_data),ord(img[6])-ord('A') ])\n",
        "       \n",
        "\n",
        "    #random.shuffle(test_data)\n",
        "    return test_data\n"
      ],
      "metadata": {
        "id": "j-ujRT0IsCax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = create_train_data()\n",
        "X_train = np.array([i[0] for i in train_images]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "y_train = np.array([i[1] for i in train_images]).reshape(-1,)\n",
        "\n",
        "test_images = create_test_data()\n",
        "X_test = np.array([i[0] for i in test_images]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "y_test = np.array([i[1] for i in test_images]).reshape(-1,)"
      ],
      "metadata": {
        "id": "eejyrnehsvU_",
        "outputId": "2a355bb6-4cea-4519-a452-b9f63d9165e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:54<00:00, 10.87s/it]\n",
            "100%|██████████| 5/5 [00:09<00:00,  1.94s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model1 = Sequential([\n",
        "        layers.Conv2D(filters = 16 ,kernel_size = (3, 3), input_shape = (IMG_SIZE, IMG_SIZE, 1), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size = (2,2)),\n",
        "\n",
        "        layers.Conv2D(filters = 32 ,kernel_size = (5, 5), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    \n",
        "        layers.Conv2D(filters = 32 ,kernel_size = (5, 5), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2,2)),\n",
        "    \n",
        "        layers.Conv2D(filters = 16 ,kernel_size = (3, 3), padding='same', activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.MaxPooling2D(pool_size=(2,2)),\n",
        "  \n",
        "        layers.Flatten(),\n",
        "        layers.Dense(1024, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        layers.Dense(5, activation = 'softmax')\n",
        "])\n",
        "\n",
        "model1.compile(\n",
        "    optimizer= tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
        "    loss=SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'])\n",
        "if (os.path.exists('/content/drive/MyDrive/person_Recognetion.h5')):\n",
        "      model1 = load_model('/content/drive/MyDrive/person_Recognetion.h5')\n",
        "else:\n",
        "      model1.fit(X_train, y_train, epochs = 25)\n",
        "      model1.save('/content/drive/MyDrive/person_Recognetion.h5')\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "fS-3mhEZt_mQ",
        "outputId": "efd9df45-6675-4390-fe82-b8983ed8389b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/keras/layers/normalization/batch_normalization.py:514: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 200 samples\n",
            "Epoch 1/25\n",
            "200/200 [==============================] - 14s 69ms/sample - loss: 2.3580 - acc: 0.4200\n",
            "Epoch 2/25\n",
            "200/200 [==============================] - 13s 65ms/sample - loss: 0.4749 - acc: 0.8350\n",
            "Epoch 3/25\n",
            "200/200 [==============================] - 13s 65ms/sample - loss: 0.1435 - acc: 0.9300\n",
            "Epoch 4/25\n",
            "200/200 [==============================] - 17s 83ms/sample - loss: 0.1276 - acc: 0.9600\n",
            "Epoch 5/25\n",
            "200/200 [==============================] - 14s 72ms/sample - loss: 0.0433 - acc: 0.9850\n",
            "Epoch 6/25\n",
            "200/200 [==============================] - 13s 65ms/sample - loss: 0.0208 - acc: 1.0000\n",
            "Epoch 7/25\n",
            "200/200 [==============================] - 13s 65ms/sample - loss: 0.0226 - acc: 0.9900\n",
            "Epoch 8/25\n",
            "200/200 [==============================] - 13s 65ms/sample - loss: 0.0189 - acc: 0.9950\n",
            "Epoch 9/25\n",
            "200/200 [==============================] - 13s 64ms/sample - loss: 0.0218 - acc: 0.9950\n",
            "Epoch 10/25\n",
            "200/200 [==============================] - 13s 65ms/sample - loss: 0.0179 - acc: 0.9950\n",
            "Epoch 11/25\n",
            "200/200 [==============================] - 13s 64ms/sample - loss: 0.0057 - acc: 1.0000\n",
            "Epoch 12/25\n",
            "200/200 [==============================] - 13s 65ms/sample - loss: 0.0137 - acc: 0.9950\n",
            "Epoch 13/25\n",
            "200/200 [==============================] - 13s 64ms/sample - loss: 0.0052 - acc: 1.0000\n",
            "Epoch 14/25\n",
            "200/200 [==============================] - 13s 65ms/sample - loss: 0.0095 - acc: 1.0000\n",
            "Epoch 15/25\n",
            "200/200 [==============================] - 13s 64ms/sample - loss: 0.0030 - acc: 1.0000\n",
            "Epoch 16/25\n",
            "200/200 [==============================] - 13s 65ms/sample - loss: 0.0039 - acc: 1.0000\n",
            "Epoch 17/25\n",
            "200/200 [==============================] - 18s 89ms/sample - loss: 0.0048 - acc: 1.0000\n",
            "Epoch 18/25\n",
            "200/200 [==============================] - 13s 65ms/sample - loss: 0.0076 - acc: 1.0000\n",
            "Epoch 19/25\n",
            "200/200 [==============================] - 13s 65ms/sample - loss: 0.0054 - acc: 1.0000\n",
            "Epoch 20/25\n",
            "200/200 [==============================] - 13s 65ms/sample - loss: 0.0020 - acc: 1.0000\n",
            "Epoch 21/25\n",
            "200/200 [==============================] - 13s 65ms/sample - loss: 0.0022 - acc: 1.0000\n",
            "Epoch 22/25\n",
            "200/200 [==============================] - 13s 65ms/sample - loss: 0.0036 - acc: 1.0000\n",
            "Epoch 23/25\n",
            "200/200 [==============================] - 13s 65ms/sample - loss: 0.0024 - acc: 1.0000\n",
            "Epoch 24/25\n",
            "200/200 [==============================] - 13s 65ms/sample - loss: 0.0022 - acc: 1.0000\n",
            "Epoch 25/25\n",
            "200/200 [==============================] - 13s 65ms/sample - loss: 0.0011 - acc: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model1.evaluate(X_test,y_test))"
      ],
      "metadata": {
        "id": "cG7HePfrstc2",
        "outputId": "148831be-4677-46c3-99bd-0ccc971ead8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.4842239737510681, 0.85]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test=model1.predict(X_test)\n",
        "print(len(X_test))\n",
        "prediction=[]\n",
        "for i in Y_test:\n",
        "  prediction.append(np.argmax(i))\n",
        "data={'image_name':column1,'label':prediction[:40]}\n",
        "print(len(column1),len(prediction))\n",
        "df_person=pd.DataFrame(data)\n",
        "print(df_person)\n"
      ],
      "metadata": {
        "id": "ImwoJGryeZMc",
        "outputId": "996c40b3-248f-44bc-9f5c-34793c8b7731",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40\n",
            "40 40\n",
            "        image_name  label\n",
            "0   personA_10.png      0\n",
            "1   personA_13.png      0\n",
            "2    personA_2.png      0\n",
            "3   personA_20.png      0\n",
            "4   personA_27.png      0\n",
            "5   personA_29.png      0\n",
            "6   personA_30.png      0\n",
            "7   personA_42.png      0\n",
            "8   personB_10.png      1\n",
            "9   personB_13.png      1\n",
            "10   personB_2.png      1\n",
            "11  personB_20.png      1\n",
            "12  personB_27.png      1\n",
            "13  personB_29.png      1\n",
            "14  personB_33.png      1\n",
            "15  personB_42.png      1\n",
            "16  personC_13.png      2\n",
            "17  personC_17.png      2\n",
            "18  personC_19.png      2\n",
            "19  personC_32.png      2\n",
            "20  personC_34.png      2\n",
            "21  personC_39.png      2\n",
            "22   personC_6.png      2\n",
            "23   personC_8.png      2\n",
            "24  personD_14.png      3\n",
            "25  personD_15.png      3\n",
            "26  personD_17.png      3\n",
            "27  personD_21.png      3\n",
            "28  personD_22.png      3\n",
            "29  personD_26.png      3\n",
            "30  personD_31.png      3\n",
            "31  personD_41.png      3\n",
            "32  personE_15.png      4\n",
            "33  personE_17.png      1\n",
            "34  personE_18.png      1\n",
            "35  personE_22.png      4\n",
            "36  personE_27.png      1\n",
            "37  personE_32.png      1\n",
            "38  personE_35.png      1\n",
            "39  personE_40.png      1\n"
          ]
        }
      ]
    }
  ]
}